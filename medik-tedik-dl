#!/usr/bin/env python3

"""Easily download images from medik-tedik.cz.

By default, images are downloaded into $HOME/Downloads.

usage:
    tedik-medik-dl gallery_url img_number

examples:
    # Download the first image from the first gallery of 2022:
    tedik-medik-dl 'http://www.medik-tedik.cz/index.php?foto=202201' 1
"""

# NOTE: I would be nice to resolve abstract-method issue in the MedikTedikGalleryParser
# pylint: disable=abstract-method

from html.parser import HTMLParser
import os
from pathlib import Path
import re
import sys
import urllib.request
import urllib.parse


class MedikTedikGalleryParser(HTMLParser):
    """Parse a gallery web page from medik-tedik.cz.

    Due to invalid (likely handmade) markup it is difficult to parse it
    by e.g. xml.etree.ElementTree.
    """

    in_date_div = False
    in_gallery_div = False
    gallery_content = {"date": "", "urls": []}

    def handle_starttag(self, tag, attrs):
        # print("Encountered a start tag:", tag, "attrs:", attrs)
        if tag == "div" and attrs:
            if attrs[0][0] == "class" and attrs[0][1] == "galerie":
                self.in_gallery_div = True
            elif attrs[0][0] == "id" and attrs[0][1] == "pata":
                self.in_gallery_div = False
            elif attrs[0][0] == "class" and attrs[0][1] == "rokh":
                self.in_date_div = True
        if (
            self.in_gallery_div
            and tag == "a"
            and attrs
            and (attrs[0][0] == "class" and attrs[0][1] == "cell")
        ):
            # A valid URL must not contain contain control characters, e.g. a whitespace.
            # urllib.parse.quote should resolve this issue.
            self.gallery_content["urls"].append(
                "http://www.medik-tedik.cz/" + urllib.parse.quote(attrs[1][1])
            )

    # def handle_endtag(self, tag):
    #     print("Encountered an end tag :", tag)

    def handle_data(self, data):
        if self.in_date_div and re.match(r"^\d{4}-\d{2}-\d{2}$", data):
            self.gallery_content["date"] = data
            self.in_date_div = False


def main():
    """Main entry point"""
    # NOTE: I would be nice to read args using argparse
    gallery_url = sys.argv[1]
    img_number = int(sys.argv[2])
    if img_number < 1:
        print(f"Image numbers start from 1; entered: {img_number}", file=sys.stderr)
        sys.exit(1)
    # NOTE: I would be nice to let user to select a different dir if needed.
    dest_dir = Path(f'{os.getenv("HOME")}/Downloads')

    print(gallery_url, img_number)

    with urllib.request.urlopen(gallery_url) as response:
        html = response.read().decode("utf-8")

    parser = MedikTedikGalleryParser()
    parser.feed(html)
    parser.close()

    # print(parser.gallery_content)
    print(parser.gallery_content["date"])
    print("images in gallery:", len(parser.gallery_content["urls"]))

    num_images_in_gallery = len(parser.gallery_content["urls"])
    if img_number > num_images_in_gallery:
        print(f"Image number out of range; images in the gallery: {num_images_in_gallery}", file=sys.stderr)
        sys.exit(1)

    for num, url in enumerate(parser.gallery_content["urls"], start=1):
        if num == img_number:
            print(num, url)

            # Create image name in the form: topic_yyyymmdd_num.ext; topics (atletika, priroda, ostatni)
            #topics = ('atletika', 'priroda', 'ostatni')
            topic = re.search(r"fotogalerie/(atletika|priroda|ostatni)/\d{4}", url).group(1)
            #print(topic)
            if not topic:
                print("Invalid topic in image URL:", url, file=sys.stderr)
                sys.exit(1)
            img_ext = os.path.splitext(url)[1]
            date_str = parser.gallery_content["date"].replace("-", "")
            img_name = f'{topic}_{date_str}_{img_number:03}{img_ext}'

            file = dest_dir / img_name
            print("saving image as", file)
            with urllib.request.urlopen(url) as response:
                file.write_bytes(response.read())


if __name__ == "__main__":
    main()
